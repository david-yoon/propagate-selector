{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import file_util\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IS_LOWERCASE = True\n",
    "DIC_MINCUT_FREQ = 12    # less equal than this frequency will not be considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/raw/hotpot/hotpot_train_v1.1.json', 'rb') as f:\n",
    "    data_train = json.load(f)\n",
    "    \n",
    "with open('../data/raw/hotpot/hotpot_dev_distractor_v1.json', 'rb') as f:\n",
    "    data_dev_distractor = json.load(f)\n",
    "\n",
    "with open('../data/raw/hotpot/hotpot_dev_fullwiki_v1.json', 'rb') as f:\n",
    "    data_dev_wiki = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_sent_to_dic(dic, sent):\n",
    "    list_tokent = word_tokenize(sent)\n",
    "    for token in list_tokent:\n",
    "        if IS_LOWERCASE:\n",
    "            token = token.lower().strip()\n",
    "        else:\n",
    "            token = token.strip() \n",
    "            \n",
    "        if token in dic:\n",
    "            dic[token] += 1\n",
    "        else:\n",
    "            dic[token] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.load('en', disable=['tagger', 'parser', 'ner', 'textcat'])\n",
    "\n",
    "# def add_sent_to_dic(dic, sent):\n",
    "#     list_tokent = nlp(sent)\n",
    "#     for token in list_tokent:\n",
    "#         if IS_LOWERCASE:\n",
    "#             token = token.text.lower().strip()\n",
    "#         else:\n",
    "#             token = token.text.strip() \n",
    "            \n",
    "#         if token in dic:\n",
    "#             dic[token] += 1\n",
    "#         else:\n",
    "#             dic[token] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dic(dic, data):\n",
    "    \n",
    "    for sample in tqdm(data):\n",
    "        add_sent_to_dic(dic, sample['question'])\n",
    "\n",
    "        for context in sample['context']:\n",
    "            add_sent_to_dic(dic, context[0])    # title of the passage\n",
    "\n",
    "            for sentence in context[1]:\n",
    "                add_sent_to_dic(dic, sentence)  # sentence in the passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 22279/90447 [03:06<09:44, 116.72it/s]"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "create_dic(dic, data_train)\n",
    "create_dic(dic, data_dev_distractor)\n",
    "create_dic(dic, data_dev_wiki)\n",
    "print('dic size:' + str(len(dic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_util.create_folder('../data/processed/hotpot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reducing dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic_ori = dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nlp_util import apply_mincut_lessequal_than\n",
    "dic_mincut = apply_mincut_lessequal_than(dic_ori, DIC_MINCUT_FREQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voca size including _PAD_ _UNK_: 138156\n"
     ]
    }
   ],
   "source": [
    "with open('../data/processed/hotpot/vocab.txt', 'w') as f:\n",
    "    f.write('_PAD_' + '\\n')\n",
    "    f.write('_UNK_' + '\\n')\n",
    "    \n",
    "    for key in dic_mincut.keys():\n",
    "        f.write(key + '\\n')\n",
    "        \n",
    "with open('../data/processed/hotpot/vocab.txt', 'r') as f:\n",
    "    read_voca = f.readlines()\n",
    "print('voca size including _PAD_ _UNK_: ' + str(len(read_voca)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open('../data/processed/hotpot/vocab.txt', 'w') as f:\n",
    "#     f.write('_PAD_' + '\\n')\n",
    "#     f.write('_UNK_' + '\\n')\n",
    "    \n",
    "#     for key in dic_mincut.keys():\n",
    "#         f.write(key + '\\n')\n",
    "        \n",
    "# with open('../data/processed/hotpot/vocab-spacy.txt', 'r') as f:\n",
    "#     read_voca = f.readlines()\n",
    "# print('voca size including _PAD_ _UNK_: ' + str(len(read_voca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "print('completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf14_p35]",
   "language": "python",
   "name": "conda-env-tf14_p35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
