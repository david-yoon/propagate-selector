{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create ELMO embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "from bilm import TokenBatcher, BidirectionalLanguageModel, weight_layers, dump_token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # small \n",
    "\n",
    "# try:\n",
    "#     file = '../data/processed/hotpot/ELMO_options.json'\n",
    "#     if os.lstat(file):\n",
    "#         os.remove(file)\n",
    "#         os.system('ln -s ../../ELMO_pretrain/elmo_2x1024_128_2048cnn_1xhighway_options.json ../data/processed/hotpot/ELMO_options.json')\n",
    "# except:\n",
    "#     os.system('ln -s ../../ELMO_pretrain/elmo_2x1024_128_2048cnn_1xhighway_options.json ../data/processed/hotpot/ELMO_options.json')\n",
    "    \n",
    "# try:\n",
    "#     file = '../data/processed/hotpot/ELMO_weights.hdf5'\n",
    "#     if os.lstat(file):\n",
    "#         os.remove(file)\n",
    "#         os.system('ln -s ../../ELMO_pretrain/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 ../data/processed/hotpot/ELMO_weights.hdf5')\n",
    "# except:\n",
    "#     os.system('ln -s ../../ELMO_pretrain/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 ../data/processed/hotpot/ELMO_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# origianl 5.5B\n",
    "\n",
    "try:\n",
    "    file = '../data/processed/hotpot/ELMO_options.json'\n",
    "    if os.lstat(file):\n",
    "        os.remove(file)\n",
    "        os.system('ln -s ../../ELMO_pretrain/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json ../data/processed/hotpot/ELMO_options.json')\n",
    "except:\n",
    "    os.system('ln -s ../../ELMO_pretrain/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json ../data/processed/hotpot/ELMO_options.json')\n",
    "    \n",
    "try:\n",
    "    file = '../data/processed/hotpot/ELMO_weights.hdf5'\n",
    "    if os.lstat(file):\n",
    "        os.remove(file)\n",
    "        os.system('ln -s ../../ELMO_pretrain/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5 ../data/processed/hotpot/ELMO_weights.hdf5')\n",
    "except:\n",
    "    os.system('ln -s ../../ELMO_pretrain/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5 ../data/processed/hotpot/ELMO_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dic size =  138156\n"
     ]
    }
   ],
   "source": [
    "with open('../data/processed/hotpot/vocab.txt') as f:\n",
    "    voca = f.readlines()\n",
    "    voca = [x.strip() for x in voca]\n",
    "print ('original dic size = ', len(voca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/processed/hotpot/vocab-elmo.txt', 'w') as f:\n",
    "    for tok in voca:\n",
    "        f.write( tok + '\\n')\n",
    "    f.write( '<S>' + '\\n')\n",
    "    f.write( '<\\S>' + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Location of pretrained LM.  Here we use the test fixtures.\n",
    "datadir = '../data/processed/hotpot/'\n",
    "options_file = os.path.join(datadir, 'ELMO_options.json')\n",
    "weight_file = os.path.join(datadir, 'ELMO_weights.hdf5')\n",
    "vocab_file =  os.path.join(datadir, 'vocab-elmo.txt')\n",
    "token_embedding_file =  os.path.join(datadir, 'ELMO_token_embeddings.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING SKIP CONNECTIONS\n"
     ]
    }
   ],
   "source": [
    "# Dump the token embeddings to a file. Run this once for your dataset.\n",
    "dump_token_embeddings(\n",
    "    vocab_file, options_file, weight_file, token_embedding_file\n",
    ")\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf14_p35]",
   "language": "python",
   "name": "conda-env-tf14_p35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
